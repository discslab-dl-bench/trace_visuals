#!/bin/bash


# Determine which python command to use depending on platform 
# I run this on both windows and linux machines
unameOut="$(uname -s)"
case "${unameOut}" in
    MINGW*)     py=py;;
    *)          py=/usr/bin/python3.8;;
esac

if [ $# -lt 3 ]
then
    echo "Usage: $0 traces_dir num_gpus workload_name"
    exit -1
fi

traces_dir=$1
num_gpus=$2
workload_name=$3

traces_basename=$(basename $traces_dir)
traces_dirname=$(dirname $traces_dir)

ta_outdir="${traces_dirname}/ta_${traces_basename}"
echo Creating $ta_outdir
mkdir -p $ta_outdir


echo -e "\nStarting data pre-processing pipeline\n"

# Run the time alignment script on the traces
# This will convert the nsecs since boot timestamps generated by bpftrace to UTC timestamps
# allowing us to combine the bpf traces with traces from other sources.
${py} align_time.py $traces_dir $ta_outdir

[[ $? -eq 1 ]] && exit 1

# Print out long bio operations. 
# Run this command without the -p flag to remove them from the trace
${py} bio_long_calls.py $ta_outdir/bio_time_aligned.out > $ta_outdir/bio_long_reads

# Check for integer overflows in the read trace
# Should not happen anymore since the traces were fixed at the source
if [[ $(grep -a "\s+\-[0-9]\s+" ${ta_outdir}/read_time_aligned.out) ]]
then 
    echo -e "Found some large negative values in the read() trace.\n"
    echo -e "Perform integer overflow fix.\n"
    ${py} vfsrw_bugfix.py $ta_outdir/read_time_aligned.out
fi

# Extract PIDs and their human readable names
${py} pid_names.py $traces_dir $ta_outdir

echo -e "####################################################################"
echo -e "split_traces_by_pid.sh: Splitting traces into individual PID files."
echo -e "####################################################################"

# Split the traces by PID
./split_traces_by_pid.sh $ta_outdir

echo -e "####################################################################"
echo -e "prepare_traces_for_timelines.sh: Format traces for timeline plotting"
echo -e "####################################################################"
# Extract timeline information and transform data for timeline plotting
./prepare_traces_for_timelines.sh $ta_outdir



echo -e "#####################################################################"
echo -e "cpu.sh, gpu.sh, cpu_gpu.py: Preparing CPU and GPU traces for plotting"
echo -e "#####################################################################"
# Process the CPU and GPU traces
./cpu.sh $traces_dir/cpu.out $ta_outdir
./gpu.sh $traces_dir/gpu.out $ta_outdir 
${py} cpu_gpu.py $traces_dir $ta_outdir $num_gpus

if [ -f "${traces_dir}/iostat.json" ]; then
    ${py} iostat_to_csv.py "${traces_dir}/iostat.json" $ta_outdir
fi

# different logging preprocess
if [[ "$workload_name" == "dlio" ]]
then
    # specific to dlio benchmark
    echo -e "####################################################################"
    echo -e "dlio_log.py: Find the right DLIO log file and get events from there"
    echo -e "####################################################################"
    if [[ ! -d $ta_outdir/mllog_data ]]
    then
        echo "Creating output directory $ta_outdir/mllog_data"
        mkdir $ta_outdir/mllog_data
    fi
    ${py} dlio_log.py $traces_dir $ta_outdir/mllog_data/
    sed -i 's/BLOCK/TRAINING/' $ta_outdir/mllog_data/timeline.csv
else 
    echo -e "####################################################################"
    echo -e "mllog.sh, mllog_UNIX_to_UTC_ts.py: Extract events from app log"
    echo -e "####################################################################"

    # For unet3d, the log file has a different name than the workload
    if [[ "$workload_name" == "unet3d" ]]
    then
        logfile="unet3d.log"
    else
        logfile=${workload_name}.log
    fi

    # Process the app log for timeline plotting
    ./mllog.sh ${traces_dir}/${logfile} $ta_outdir $workload_name
    ${py} mllog_UNIX_to_UTC_ts.py $ta_outdir/mllog_data/
    # Used only for BERT in practice, but won't change the others
    sed -i 's/BLOCK/TRAINING/' $ta_outdir/mllog_data/timeline.csv
fi

echo -e "Preprocessing DONE\n"