#!/bin/bash


# Determine which python command to use depending on platform 
# I run this on both windows and linux machines
unameOut="$(uname -s)"
case "${unameOut}" in
    MINGW*)     py=py;;
    *)          py=python3;;
esac

if [ $# -lt 3 ]
then
    echo "Usage: $0 traces_dir num_gpus workload_name"
    echo "Note: workload_name only supports: dlio, imseg. Add your way of handling log if you feel like to!"
    exit -1
fi


traces_dir=$1

traces_basename=$(basename $traces_dir)
traces_dirname=$(dirname $traces_dir)

ta_outdir="${traces_dirname}/ta_${traces_basename}"
echo Creating $ta_outdir
mkdir -p $ta_outdir

num_gpus=$2

echo -e "\nStarting data pre-processing pipeline\n"

# Run the time alignment script on the traces
# This will convert the nsecs since boot timestamps generated by bpftrace to UTC timestamps
# allowing us to combine the bpf traces with traces from other sources.
${py} align_time.py $traces_dir $ta_outdir

# Check for integer overflows in the read trace
# Should not happen anymore since the traces were fixed at the source
if [[ $(grep -a "\s+\-[0-9]\s+" ${ta_outdir}/read_time_aligned.out) ]]
then 
    echo -e "Found some large negative values in the read() trace.\n"
    echo -e "Perform integer overflow fix.\n"
    ${py} vfsrw_bugfix.py $ta_outdir/read_time_aligned.out
fi

# Extract PIDs and their human readable names
${py} pid_names.py $traces_dir $ta_outdir

echo -e "####################################################################"
echo -e "split_traces_by_pid.sh: Splitting traces into individual PID files."
echo -e "####################################################################"

# Split the traces by PID
./split_traces_by_pid.sh $ta_outdir

echo -e "####################################################################"
echo -e "prepare_traces_for_timelines.sh: Format traces for timeline plotting"
echo -e "####################################################################"
# Extract timeline information and transform data for timeline plotting
./prepare_traces_for_timelines.sh $ta_outdir

echo -e "#####################################################################"
echo -e "cpu.sh, gpu.sh, cpu_gpu.py: Preparing CPU and GPU traces for plotting"
echo -e "#####################################################################"
# Process the CPU and GPU traces
./cpu.sh $traces_dir/cpu.out $ta_outdir
./gpu.sh $traces_dir/gpu.out $ta_outdir 
${py} cpu_gpu.py $ta_outdir/gpu_data/gpu.all $ta_outdir/cpu_data/cpu.all $num_gpus


# different logging preprocess
if [[ "$workload_name" == "dlio" ]]
then
    # specific to dlio benchmark
    echo -e "####################################################################"
    echo -e "dlio_log.py: Find the right DLIO log file and get events from there"
    echo -e "####################################################################"
    if [[ ! -d $ta_outdir/mllog_data ]]
    then
        echo "Creating output directory $ta_outdir/mllog_data"
        mkdir $ta_outdir/mllog_data
    fi
    ${py} dlio_log.py $traces_dir $ta_outdir/mllog_data/
elif [[ "$workload_name" == "imseg" ]]
then
    # specific to unet3d workload only!
    echo -e "####################################################################"
    echo -e "mllog.sh, mllog_UNIX_to_UTC_ts.py: Extract events from imseg app log"
    echo -e "####################################################################"
    # Process the app log for timeline plotting
    ./mllog.sh $traces_dir/unet3d.log $ta_outdir
    ${py} mllog_UNIX_to_UTC_ts.py $ta_outdir/mllog_data/
#elif.... for your own workload log files
fi


echo -e "Preprocessing DONE\n"